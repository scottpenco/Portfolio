{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG vs Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import GrobidParser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open AI KEY\n",
    "openai_api_key = ##Removed for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline and Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from Grobid\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    \"/Users/Scott/Downloads/test input/\",\n",
    "    glob=\"*\",\n",
    "    suffixes=[\".pdf\"],\n",
    "    parser=GrobidParser(segment_sentences=False),\n",
    ")\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'In this paper, we introduce Dynamically Rewired Message Passing (DRew), a novel framework for layer-dependent, multi-hop message passing that takes a principled approach to information flow, is robust to over-squashing, and can be applied to any MPNN for deep learning on graphs.',\n",
       " 'para': '0',\n",
       " 'bboxes': \"[[{'page': '1', 'x': '307.44', 'y': '303.89', 'h': '234.00', 'w': '9.03'}, {'page': '1', 'x': '307.44', 'y': '315.85', 'h': '235.25', 'w': '9.03'}, {'page': '1', 'x': '307.44', 'y': '328.19', 'h': '234.00', 'w': '8.64'}, {'page': '1', 'x': '307.44', 'y': '340.15', 'h': '234.00', 'w': '8.64'}, {'page': '1', 'x': '307.44', 'y': '352.10', 'h': '202.11', 'w': '8.64'}]]\",\n",
       " 'pages': \"('1', '1')\",\n",
       " 'section_title': 'Introduction',\n",
       " 'section_number': '1.',\n",
       " 'paper_title': 'DRew: Dynamically Rewired Message Passing with Delay',\n",
       " 'file_path': '/Users/Scott/Downloads/test input/2305.08018v2.pdf'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking Metadata\n",
    "data[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
    "import os\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the document using RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap = 100) #CHANGE CHUNK SIZE?\n",
    "docs = splitter.split_documents(data) \n",
    "\n",
    "#Embed the documents in a persistent Chroma vector Database\n",
    "embedding_function = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=os.getcwd()\n",
    ")\n",
    "\n",
    "\n",
    "#Configure the vectore sotre as a retriever \n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add placeholders to the message string\n",
    "message = \"\"\"\n",
    "Answer the following question using the context provided:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create a chat prompt template from the message string\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"human\", message)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researchers should consider the following factors when fine-tuning pre-trained models on datasets from diverse atomic domains:\n",
      "\n",
      "1. **Dataset Selection**: Choose datasets that cover a wide range of atomic domains to ensure generalization of the pre-trained models. In the provided context, datasets were selected from materials, small molecules, and large molecules domains.\n",
      "\n",
      "2. **Task Diversity**: Select a diverse set of fine-tuning tasks within each atomic domain to test the generalization capabilities of the pre-trained models effectively.\n",
      "\n",
      "3. **Model Architecture**: Ensure that the pre-trained model architecture is suitable for the specific atomic domains being considered. Fine-tuning on diverse datasets may require adjustments or optimization of the model architecture.\n",
      "\n",
      "4. **Hyperparameter Tuning**: Optimize hyperparameters during fine-tuning to achieve better performance across different atomic domains. Fine-tuning on diverse datasets may require specific hyperparameter settings for optimal results.\n",
      "\n",
      "5. **Evaluation Metrics**: Use appropriate evaluation metrics that are relevant to the atomic domains under consideration. Different domains may require different evaluation criteria for measuring model performance accurately.\n",
      "\n",
      "6. **Transfer Learning Techniques**: Explore various transfer learning techniques to adapt the pre-trained models to new atomic domains effectively. Techniques such as domain adaptation or multi-task learning may be beneficial for fine-tuning on diverse datasets.\n",
      "\n",
      "7. **Data Preprocessing**: Preprocess the data carefully to ensure compatibility with the pre-trained models and to address any domain-specific challenges or biases present in the datasets from diverse atomic domains.\n",
      "\n",
      "By considering these factors, researchers can enhance the generalization capabilities of pre-trained models when fine-tuning them on datasets from diverse atomic domains.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7, openai_api_key=openai_api_key)\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks specifically about the provided PDF documents.\"\n",
    "    \"Use the following pieces of retrieved context to answer the questions.\"\n",
    "    \"Use as many PDF documents loaded as possible\"\n",
    "    \"Do not use any external knowledge or information outside of the PDF loaded.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"What considerations should researchers take into account when fine-tuning pre-trained models on datasets from diverse atomic domains?\"})\n",
    "rag_message = response['answer']\n",
    "print(rag_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=openai_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File path for Training and Validation Prompts in JSONL format\n",
    "training_file_name = \"/Users/Scott/Documents/Python/Homework/Finetuning/trainingprompts2.jsonl\"\n",
    "validation_file_name = \"/Users/Scott/Documents/Python/Homework/Finetuning/validationprompts.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            messages\n",
      "0  [{'role': 'system', 'content': 'An assistant c...\n",
      "1  [{'role': 'system', 'content': 'An assistant c...\n",
      "2  [{'role': 'system', 'content': 'An assistant c...\n",
      "3  [{'role': 'system', 'content': 'An assistant c...\n",
      "4  [{'role': 'system', 'content': 'An assistant c...\n",
      "5  [{'role': 'system', 'content': 'An assistant c...\n",
      "6  [{'role': 'system', 'content': 'An assistant c...\n",
      "7  [{'role': 'system', 'content': 'An assistant c...\n",
      "8  [{'role': 'system', 'content': 'An assistant c...\n",
      "9  [{'role': 'system', 'content': 'An assistant c...\n"
     ]
    }
   ],
   "source": [
    "#Printing head of Training Prompts\n",
    "training_prompts = pd.read_json(training_file_name, lines=True)\n",
    "print(training_prompts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            messages\n",
      "0  [{'role': 'system', 'content': 'An assistant c...\n",
      "1  [{'role': 'system', 'content': 'An assistant c...\n",
      "2  [{'role': 'system', 'content': 'An assistant c...\n",
      "3  [{'role': 'system', 'content': 'An assistant c...\n",
      "4  [{'role': 'system', 'content': 'An assistant c...\n"
     ]
    }
   ],
   "source": [
    "#Printing head of Validation Prompts\n",
    "validation_prompts = pd.read_json(validation_file_name, lines=True)\n",
    "print(validation_prompts.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training File: FileObject(id='file-pC79JuTTgRUwW60nvOp7MY4P', bytes=32906, created_at=1726143512, filename='trainingprompts2.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Validation File: FileObject(id='file-AZjWuOECv5v9YBYEq8LfwEnw', bytes=12494, created_at=1726143513, filename='validationprompts.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "#Uploading Training and Validation JSNOL files to OPEN AI Client \n",
    "training_file_id = client.files.create(\n",
    "  file=open(training_file_name, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "validation_file_id = client.files.create(\n",
    "  file=open(validation_file_name, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "#Pringing Training and Validation File IDs\n",
    "print(f\"Training File: {training_file_id}\")\n",
    "print(f\"Validation File: {validation_file_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Response: FineTuningJob(id='ftjob-UWnIEWAhixlmajG719m18S7T', created_at=1726143515, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=15, batch_size=3, learning_rate_multiplier=0.3), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-4rTIJZ8QzdOrbetyoHq0qqB1', result_files=[], seed=2089879020, status='validating_files', trained_tokens=None, training_file='file-pC79JuTTgRUwW60nvOp7MY4P', validation_file='file-AZjWuOECv5v9YBYEq8LfwEnw', estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "#Creating Fine-Tuning model Job\n",
    "model_training_response = client.fine_tuning.jobs.create(\n",
    "  training_file=training_file_id.id, \n",
    "  validation_file=validation_file_id.id,\n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  hyperparameters={\n",
    "    \"n_epochs\": 15,\n",
    "\t\"batch_size\": 3,\n",
    "\t\"learning_rate_multiplier\": 0.3\n",
    "  }\n",
    ")\n",
    "print(f\"Training Response: {model_training_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One major consideration is the interpretability of GCN predictions for drug-target interactions. Model explainability is crucial in understanding how molecular features influence predictions.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0125:personal::A1DibUK6\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"An assistant chatbot trained on academic papers used to answer questions that intersect AI and Drug Discovery with respect to Graph Theory and Molecular Modelling\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are somethings that i need to be careful about when using GCNs and drug discovery?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responses are compared: \n",
    "Finetuning vs Basemodel\n",
    "Finetuning vs RAG \n",
    "\n",
    "Answers are ranked by a LLM to determine the quality of the answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"An assistant chatbot trained on academic papers used to answer questions that intersect AI and Drug Discovery with respect to Graph Theory and Molecular Modelling\"},\n",
    "    {\"role\": \"user\", \"content\": \"What considerations should researchers take into account when fine-tuning pre-trained models on datasets from diverse atomic domains?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When fine-tuning pre-trained models on datasets from diverse atomic domains in the context of AI and Drug Discovery, researchers should consider the following key considerations:\n",
      "\n",
      "1. **Domain-specific features**: Different atomic domains may have unique features and characteristics. Researchers should carefully analyze and understand the specific features of the atomic domains they are working with to ensure the pre-trained models can capture domain-specific patterns effectively during fine-tuning.\n",
      "\n",
      "2. **Data preprocessing**: Preprocessing techniques such as normalization, feature scaling, and data augmentation may need to be adapted to suit the characteristics of the diverse atomic domains. This step is crucial to ensure that the pre-trained models can generalize well to new datasets from different atomic domains.\n",
      "\n",
      "3. **Transfer learning strategies**: Researchers should consider appropriate transfer learning strategies to fine-tune pre-trained models effectively on diverse atomic domains. This may involve choosing the right pre-trained model architecture, adjusting learning rates, and deciding which layers to freeze or fine-tune during the training process.\n",
      "\n",
      "4. **Evaluation metrics**: It is important to select appropriate evaluation metrics that are relevant to the specific atomic domains under consideration. Researchers should define evaluation metrics that align with the objectives of the drug discovery tasks and ensure that the fine-tuned models are performing well across diverse atomic domains.\n",
      "\n",
      "5. **Regularization techniques**: Regularization techniques such as dropout, weight decay, and early stopping can help prevent overfitting when fine-tuning pre-trained models on datasets from diverse atomic domains. Researchers should experiment with different regularization techniques to find the optimal balance between model complexity and generalization.\n",
      "\n",
      "By considering these key considerations, researchers can effectively fine-tune pre-trained models on datasets from diverse atomic domains in the context of AI and Drug Discovery, ultimately improving the performance and generalization capabilities of the models for a wide range of applications.\n"
     ]
    }
   ],
   "source": [
    "base_message = base_response.choices[0].message.content\n",
    "print(base_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GPT for evaulation of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"An assistant chatbot used to evaluate answers and rank them on a scale of 1-5. Rate the responses based on quality of the response and logic behind the response. \"},\n",
    "    {\"role\": \"user\", \"content\": rag_message }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a detailed and comprehensive response that covers essential factors for researchers to consider when fine-tuning pre-trained models on datasets from diverse atomic domains. Each point is clearly articulated and provides a logical reasoning behind it. The response not only highlights the key considerations but also explains why they are crucial for achieving better performance and generalization of models across different atomic domains. Overall, this response demonstrates a strong understanding of the topic and presents the information in a structured and informative manner.\n",
      "\n",
      "I would rate this response a 5 out of 5 for its quality and thoroughness.\n"
     ]
    }
   ],
   "source": [
    "eval_message = eval_response.choices[0].message.content\n",
    "print(eval_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grobid_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
